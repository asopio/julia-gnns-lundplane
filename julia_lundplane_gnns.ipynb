{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Neural Networks on the Lund Plane in Julia! \n",
    "\n",
    "TODO:\n",
    " - Run on GPU machine using CUDA [x]\n",
    " - Try to parallelise pre-procesing step on GPU02 -- there are 32 CPU cores [x]\n",
    " - Implement a new GNN layer that performs CA re-clustering after EdgeConv operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To install everything on a new machine\n",
    "# import Pkg\n",
    "# Pkg.add([\"Flux\",\"Statistics\",\"StatsBase\",\"GraphNeuralNetworks\", \"CUDA\", \n",
    "#          \"Graphs\",\"MLUtils\",\"Plots\",\"GraphMakie\",\"CairoMakie\", \"UnROOT\", \"Trapz\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# using ProgressMeter\n",
    "using Flux, Statistics, StatsBase, GraphNeuralNetworks, Graphs, MLUtils, Plots, CUDA\n",
    "using Flux.Data: DataLoader\n",
    "using GraphMakie, CairoMakie\n",
    "using Trapz, Printf\n",
    "using UnROOT #Julia native package for reading root files\n",
    "import Interpolations\n",
    "using Random\n",
    "using Glob\n",
    "using BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "load_chunk_from_rootfiles (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"lundplane_utils.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Check how many threads we're running on\n",
    "# Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open LJP data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # f_sig = ROOTFile(\"../Downloads/ntuples_test/wprime/user.asopio.24603642._000001.ANALYSIS.root\")\n",
    "# # f_bkg = ROOTFile(\"../Downloads/ntuples_test/dijets/user.asopio.24603630._000002.ANALYSIS.root\")\n",
    "# f_sig = ROOTFile(\"/unix/atlas2/asopio/lundNtuples_20210322/user.asopio.grid_wprime_trees_ufosd.426347.Pythia8EvtGen_A14NNPDF23LO_WprimeWZ_flatpT_ANALYSIS.root/user.asopio.24603642._000001.ANALYSIS.root\")\n",
    "# f_bkg = ROOTFile(\"/unix/atlas2/asopio/lundNtuples_20210322/user.asopio.grid_dijet_trees_ufosd.364706.Pythia8EvtGen_A14NNPDF23LO_jetjet_JZ6WithSW_ANALYSIS.root/user.asopio.24603630._000002.ANALYSIS.root\")\n",
    "\n",
    "# brkeys = [\"Akt10TruthChargedJet_jetLundZ\", \"Akt10TruthChargedJet_jetLundDeltaR\", \"Akt10TruthChargedJet_jetLundKt\", \n",
    "#           \"Akt10TruthChargedJet_jetLundPt1\", \"Akt10TruthChargedJet_jetLundPt2\", \"Akt10TruthChargedJet_jetLundE\",\n",
    "#           \"Akt10TruthJet_jetM\", \"Akt10TruthJet_jetPt\", \"Akt10TruthChargedJet_jetLundIDParent1\", \n",
    "#           \"Akt10TruthChargedJet_jetLundIDParent2\"]\n",
    "\n",
    "# tname = \"lundjets_InDetTrackParticles\"\n",
    "\n",
    "# t_sig = LazyTree(f_sig, tname, brkeys)\n",
    "# t_bkg = LazyTree(f_bkg, tname, brkeys)\n",
    "\n",
    "# \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# t_sig[1].Akt10TruthJet_jetM[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nsamp = 10000\n",
    "\n",
    "# t = @elapsed begin\n",
    "\n",
    "# sig_samples = make_graphs_from_ttree( t_sig, nsamp, lab=1 )\n",
    "# bkg_samples = make_graphs_from_ttree( t_bkg, nsamp, lab=0 )\n",
    "    \n",
    "# end\n",
    "# println( \"Seconds to generate dataset graphs \", t )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "device = CUDA.functional() ? Flux.gpu : Flux.cpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam(9.999999747378752e-5, (0.9, 0.999), 1.0e-8, IdDict{Any, Any}())"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"model_bsons/myGNN_6LPfeats_v3\"\n",
    "\n",
    "# device = Flux.cpu;\n",
    "model = GNNChain( EdgeConv( Dense(12,64) ), #GCNConv(16 => 64), #EdgeConv( Dense(16,16) ), \n",
    "#                   BatchNorm(64),     # Apply batch normalization on node features (nodes dimension is batch dimension)\n",
    "                  x -> relu.(x),\n",
    "                  EdgeConv( Dense(128,64) ),\n",
    "                  x -> relu.(x),\n",
    "                  EdgeConv( Dense(128,128) ),\n",
    "                  x -> relu.(x),\n",
    "                  #GCNConv(64 => 64, relu),\n",
    "                  GlobalPool(mean),  # aggregate node-wise features into graph-wise features\n",
    "                  Dense(128, 256), \n",
    "                  Dense(256, 256), \n",
    "                  Dense(256, 1), \n",
    "                  x -> sigmoid(x) )#Sigmoid since we need values in [0-1]\n",
    "\n",
    "ps = Flux.params(model)\n",
    "# opt = Adam(1f-4)\n",
    "opt = Flux.Optimise.Adam(1f-4)\n",
    "# opt = Flux.Optimise.Descent(1f-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124673"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(length, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model model_bsons/myGNN_6LPfeats_v3_0.bson"
     ]
    }
   ],
   "source": [
    "outfname = string(model_name,\"_0.bson\")\n",
    "print(\"Saving model \", outfname)\n",
    "BSON.@save outfname model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model model_bsons/myGNN_6LPfeats_v3_11.bson\n"
     ]
    }
   ],
   "source": [
    "#Load the latest epoch of the model\n",
    "saved_models = glob(model_name * \"*\")\n",
    "max_saved_epoch = maximum([ parse(Int64,split(m,\"_\")[end][1:end-5]) for m in saved_models ])\n",
    "println(\"Loading model \", \"$(model_name)_$(max_saved_epoch).bson\")\n",
    "BSON.@load \"$(model_name)_$(max_saved_epoch).bson\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNChain(EdgeConv(Dense(12 => 64), aggr=max), #6, EdgeConv(Dense(128 => 64), aggr=max), #7, EdgeConv(Dense(128 => 128), aggr=max), #8, GlobalPool{typeof(mean)}(Statistics.mean), Dense(128 => 256), Dense(256 => 256), Dense(256 => 1), #9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CUDA.reclaim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 50 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 1, train_loss = 0.2228989f0, test_loss = 0.21674263f0, dloss = 998.7771f0, seconds_per_chunk = 0.0, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 2, train_loss = 0.22294189f0, test_loss = 0.22145145f0, dloss = -4.298985f-5, seconds_per_chunk = 119.203391926, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 3, train_loss = 0.2225648f0, test_loss = 0.22487965f0, dloss = 0.00037708879f0, seconds_per_chunk = 22.583294814, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 4, train_loss = 0.22227429f0, test_loss = 0.22642002f0, dloss = 0.00029051304f0, seconds_per_chunk = 22.956784675, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 5, train_loss = 0.2231141f0, test_loss = 0.22305323f0, dloss = -0.00083981454f0, seconds_per_chunk = 24.477878922, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 6, train_loss = 0.20838696f0, test_loss = 0.2082473f0, dloss = 0.014727145f0, seconds_per_chunk = 23.153383135, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 7, train_loss = 0.20724288f0, test_loss = 0.21326575f0, dloss = 0.0011440814f0, seconds_per_chunk = 24.727359554, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 8, train_loss = 0.20687719f0, test_loss = 0.20797762f0, dloss = 0.0003656894f0, seconds_per_chunk = 25.029133714, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 9, train_loss = 0.20711426f0, test_loss = 0.22253276f0, dloss = -0.00023707747f0, seconds_per_chunk = 24.140430853, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 10, train_loss = 0.20594847f0, test_loss = 0.21965694f0, dloss = 0.0011657923f0, seconds_per_chunk = 24.5886276, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 11, train_loss = 0.20722522f0, test_loss = 0.21243647f0, dloss = -0.0012767464f0, seconds_per_chunk = 25.378737787, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 12, train_loss = 0.20753986f0, test_loss = 0.22633255f0, dloss = -0.00031463802f0, seconds_per_chunk = 24.195440753, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 13, train_loss = 0.2041207f0, test_loss = 0.21701066f0, dloss = 0.0034191608f0, seconds_per_chunk = 24.585787607, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 14, train_loss = 0.19836742f0, test_loss = 0.21168411f0, dloss = 0.0057532787f0, seconds_per_chunk = 25.803427011, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 15, train_loss = 0.19779664f0, test_loss = 0.20844074f0, dloss = 0.0005707741f0, seconds_per_chunk = 34.058927618, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 16, train_loss = 0.19905904f0, test_loss = 0.206532f0, dloss = -0.0012623966f0, seconds_per_chunk = 31.040105577, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 17, train_loss = 0.1995752f0, test_loss = 0.21008813f0, dloss = -0.0005161613f0, seconds_per_chunk = 29.365843007, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 18, train_loss = 0.19846514f0, test_loss = 0.21088578f0, dloss = 0.001110062f0, seconds_per_chunk = 41.895791383, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 19, train_loss = 0.1984332f0, test_loss = 0.21953732f0, dloss = 3.193319f-5, seconds_per_chunk = 30.280330967, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 20, train_loss = 0.19877875f0, test_loss = 0.20022523f0, dloss = -0.00034554303f0, seconds_per_chunk = 33.284564158, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 21, train_loss = 0.19906448f0, test_loss = 0.198426f0, dloss = -0.00028572977f0, seconds_per_chunk = 38.398375742, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 22, train_loss = 0.1943643f0, test_loss = 0.20095651f0, dloss = 0.004700184f0, seconds_per_chunk = 34.350703142, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 23, train_loss = 0.1942488f0, test_loss = 0.2031931f0, dloss = 0.0001154989f0, seconds_per_chunk = 64.057021947, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 24, train_loss = 0.19487137f0, test_loss = 0.20250534f0, dloss = -0.0006225705f0, seconds_per_chunk = 41.270014429, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 25, train_loss = 0.1941962f0, test_loss = 0.19768314f0, dloss = 0.0006751716f0, seconds_per_chunk = 76.598634761, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 26, train_loss = 0.19484948f0, test_loss = 0.19072765f0, dloss = -0.0006532818f0, seconds_per_chunk = 60.241962087, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 27, train_loss = 0.19328003f0, test_loss = 0.19789039f0, dloss = 0.0015694499f0, seconds_per_chunk = 61.453606254, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 28, train_loss = 0.19275914f0, test_loss = 0.20319785f0, dloss = 0.000520885f0, seconds_per_chunk = 46.081518427, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 29, train_loss = 0.19042127f0, test_loss = 0.19711134f0, dloss = 0.002337873f0, seconds_per_chunk = 67.398923519, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 30, train_loss = 0.19007875f0, test_loss = 0.19354577f0, dloss = 0.0003425181f0, seconds_per_chunk = 72.503992686, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 31, train_loss = 0.19019136f0, test_loss = 0.19448191f0, dloss = -0.000112608075f0, seconds_per_chunk = 92.104693616, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 32, train_loss = 0.18823043f0, test_loss = 0.19221433f0, dloss = 0.0019609332f0, seconds_per_chunk = 80.067336093, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 33, train_loss = 0.18779035f0, test_loss = 0.18740389f0, dloss = 0.000440076f0, seconds_per_chunk = 78.83188194, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 34, train_loss = 0.18783271f0, test_loss = 0.20348458f0, dloss = -4.2364f-5, seconds_per_chunk = 99.156029171, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 35, train_loss = 0.18787491f0, test_loss = 0.18544738f0, dloss = -4.220009f-5, seconds_per_chunk = 91.399994985, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 36, train_loss = 0.18681261f0, test_loss = 0.18808508f0, dloss = 0.0010623038f0, seconds_per_chunk = 98.143439633, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 37, train_loss = 0.18513651f0, test_loss = 0.18886079f0, dloss = 0.0016760975f0, seconds_per_chunk = 96.228496231, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 38, train_loss = 0.18525466f0, test_loss = 0.19374144f0, dloss = -0.00011815131f0, seconds_per_chunk = 102.356618884, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 39, train_loss = 0.18610801f0, test_loss = 0.19727297f0, dloss = -0.0008533448f0, seconds_per_chunk = 104.079340513, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 40, train_loss = 0.18554252f0, test_loss = 0.18945234f0, dloss = 0.00056548417f0, seconds_per_chunk = 90.243000369, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 41, train_loss = 0.1847724f0, test_loss = 0.18500061f0, dloss = 0.0007701218f0, seconds_per_chunk = 99.795407904, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 42, train_loss = 0.1849858f0, test_loss = 0.19565094f0, dloss = -0.00021339953f0, seconds_per_chunk = 103.361609186, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 43, train_loss = 0.1831872f0, test_loss = 0.19472525f0, dloss = 0.0017986f0, seconds_per_chunk = 97.528019844, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 44, train_loss = 0.18413411f0, test_loss = 0.19106533f0, dloss = -0.0009469092f0, seconds_per_chunk = 107.928005228, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 45, train_loss = 0.18448712f0, test_loss = 0.20290996f0, dloss = -0.0003530085f0, seconds_per_chunk = 101.791974903, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 46, train_loss = 0.18401112f0, test_loss = 0.19519886f0, dloss = 0.0004760027f0, seconds_per_chunk = 105.989505815, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 47, train_loss = 0.18345328f0, test_loss = 0.19079027f0, dloss = 0.00055783987f0, seconds_per_chunk = 84.326487074, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 48, train_loss = 0.18282719f0, test_loss = 0.18137677f0, dloss = 0.0006260872f0, seconds_per_chunk = 93.455457453, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 49, train_loss = 0.18340978f0, test_loss = 0.18813479f0, dloss = -0.0005825907f0, seconds_per_chunk = 106.928437221, seconds_per_epoch = 0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model model_bsons/myGNN_6LPfeats_v3_11.bson"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 11, ch = 50, train_loss = 0.18335491f0, test_loss = 0.18858157f0, dloss = 5.4866076f-5, seconds_per_chunk = 104.988067692, seconds_per_epoch = 0.0)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 1, train_loss = 0.22290182f0, test_loss = 0.21674263f0, dloss = -0.039546907f0, seconds_per_chunk = 89.020010307, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 2, train_loss = 0.2229419f0, test_loss = 0.22145148f0, dloss = -4.0084124f-5, seconds_per_chunk = 22.692477723, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 3, train_loss = 0.22256482f0, test_loss = 0.22487973f0, dloss = 0.00037708879f0, seconds_per_chunk = 23.240786478, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 4, train_loss = 0.22227426f0, test_loss = 0.22641999f0, dloss = 0.00029055774f0, seconds_per_chunk = 23.284128892, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 5, train_loss = 0.2231141f0, test_loss = 0.22305325f0, dloss = -0.00083984435f0, seconds_per_chunk = 23.853257178, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 6, train_loss = 0.20838694f0, test_loss = 0.2082473f0, dloss = 0.01472716f0, seconds_per_chunk = 22.670908872, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 7, train_loss = 0.20724289f0, test_loss = 0.2132657f0, dloss = 0.0011440516f0, seconds_per_chunk = 24.607987651, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 8, train_loss = 0.20687723f0, test_loss = 0.20797761f0, dloss = 0.0003656596f0, seconds_per_chunk = 25.442019454, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 9, train_loss = 0.20711425f0, test_loss = 0.22253276f0, dloss = -0.00023701787f0, seconds_per_chunk = 24.215316372, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 10, train_loss = 0.20594846f0, test_loss = 0.21965696f0, dloss = 0.0011657923f0, seconds_per_chunk = 24.694867896, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 11, train_loss = 0.20722522f0, test_loss = 0.21243645f0, dloss = -0.0012767613f0, seconds_per_chunk = 25.51828871, seconds_per_epoch = 3200.828148853)\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39m(epoch = 12, ch = 12, train_loss = 0.20753987f0, test_loss = 0.22633256f0, dloss = -0.00031465292f0, seconds_per_chunk = 24.261193388, seconds_per_epoch = 3200.828148853)\n"
     ]
    }
   ],
   "source": [
    "loss(g::GNNGraph) = mean((vec(model(g, g.ndata.x)) - g.gdata.y).^2)\n",
    "loss(loader) = mean(loss(g |> device) for g in loader)\n",
    "\n",
    "#Number of chunks        \n",
    "nch = 50\n",
    "\n",
    "#globs for signal/background samples\n",
    "gl_sig = \"../lundNtuples_20210322/user.asopio.grid_wprime*_ANALYSIS.root/*\"\n",
    "gl_bkg = \"../lundNtuples_20210322/user.asopio.grid_dijet*_ANALYSIS.root/*\"\n",
    "        \n",
    "#Batch size for training\n",
    "# bs=1024 * 2\n",
    "bs=128\n",
    "        \n",
    "test_losses = Float32[ 999.0 ]\n",
    "train_losses = Float32[ 999.0 ]\n",
    "\n",
    "nepochs = 25\n",
    "prev_train_loss = 999\n",
    "min_epoch = maximum((1,max_saved_epoch))\n",
    "        \n",
    "t_ep = 0.0\n",
    "t_ch = 0.0\n",
    "\n",
    "#load the model onto the device        \n",
    "model = device(model) \n",
    "        \n",
    "println(\"Training on \", nch, \" chunks\")\n",
    "for epoch in min_epoch:nepochs\n",
    "    t_ep = @elapsed begin\n",
    "        for ich in 1:nch                    \n",
    "            t_ch = @elapsed begin  \n",
    "                sig_samples = load_chunk_from_rootfiles( gl_sig, nch, ich, 1.0 )\n",
    "                bkg_samples = load_chunk_from_rootfiles( gl_bkg, nch, ich, 0.0 )\n",
    "\n",
    "                all_samples = GNNGraph[]\n",
    "                append!( all_samples, sig_samples )\n",
    "                append!( all_samples, bkg_samples )\n",
    "\n",
    "                Random.seed!(1234)\n",
    "                train_graphs, test_graphs = MLUtils.splitobs(all_samples, at=0.99, shuffle=true)\n",
    "\n",
    "                train_loader = DataLoader(train_graphs, \n",
    "                                batchsize=bs, shuffle=true, collate=true)\n",
    "                test_loader = DataLoader(test_graphs, \n",
    "                                batchsize=bs, shuffle=false, collate=true)\n",
    "\n",
    "#                 CUDA.@time begin\n",
    "                            \n",
    "#                 batch_train_losses = Float32[]        \n",
    "                #Train loop\n",
    "                for g in train_loader\n",
    "                    g = g |> device\n",
    "                    grad = Flux.gradient(() -> loss(g), ps)\n",
    "                    Flux.Optimise.update!(opt, ps, grad)\n",
    "                end\n",
    "                \n",
    "                train_loss = loss( train_loader ) #Only evaluate losses on first batch for speed\n",
    "                test_loss = loss( test_loader )\n",
    "                        \n",
    "#                 train_loss = loss( first(train_loader) |> device ) #Only evaluate losses on first batch for speed\n",
    "#                 test_loss = loss( first(test_loader) |> device )\n",
    "                            \n",
    "#                 end\n",
    "                            \n",
    "                push!( train_losses, train_loss )\n",
    "                push!( test_losses, test_loss )\n",
    "                        \n",
    "                @info (; epoch, ch=ich, train_loss=train_loss, test_loss=test_loss, \n",
    "                         dloss=train_losses[end-1] - train_loss, seconds_per_chunk=t_ch, seconds_per_epoch=t_ep)\n",
    "                        \n",
    "            end\n",
    "        end            \n",
    "    end\n",
    "            \n",
    "    outfname = string(model_name,\"_\",epoch,\".bson\")\n",
    "    print(\"Saving model \", outfname)\n",
    "    let model = cpu(model)\n",
    "        BSON.@save outfname model        \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot losses\n",
    "Plots.plot(train_losses; label=\"train loss\", xlabel=\"epoch\", ylabel=\"MSE loss\", linewidth=2, yaxis=:log, ylim=[10^-1.8, 10^-1.2])\n",
    "Plots.plot!(test_losses; label=\"test loss\", linewidth=2)\n",
    "Plots.plot!([ mean(train_losses[max(1,i):min(end,i+50)]) for i in 1:length(train_losses)-50 ], label=\"Train loss 50 ch. mov. avg.\")\n",
    "Plots.plot!([ mean(test_losses[max(1,i):min(end,i+50)]) for i in 1:length(test_losses)-50 ], label=\"Test loss 50 ch. mov. avg.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
